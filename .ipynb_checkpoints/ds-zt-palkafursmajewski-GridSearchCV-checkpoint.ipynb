{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok - import\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "print('Ok - import')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.51 GiB for an array with shape (69, 23563668) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m ddf_train \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mread_parquet(train_path, columns\u001b[38;5;241m=\u001b[39mfeatures \u001b[38;5;241m+\u001b[39m [target_train, weights])\n\u001b[0;32m     15\u001b[0m data_train \u001b[38;5;241m=\u001b[39m ddf_train\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39mpercent_of_dataset, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m---> 16\u001b[0m data_train \u001b[38;5;241m=\u001b[39m \u001b[43mdata_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Usunięcie braków\u001b[39;00m\n\u001b[0;32m     18\u001b[0m X_train \u001b[38;5;241m=\u001b[39m data_train[features]\n\u001b[0;32m     19\u001b[0m y_train \u001b[38;5;241m=\u001b[39m data_train[target_train]\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\pandas\\core\\frame.py:6678\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6675\u001b[0m     mask \u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m thresh\n\u001b[0;32m   6676\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   6677\u001b[0m     \u001b[38;5;66;03m# faster equivalent to 'agg_obj.count(agg_axis) == self.shape[agg_axis]'\u001b[39;00m\n\u001b[1;32m-> 6678\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43magg_obj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mall(axis\u001b[38;5;241m=\u001b[39magg_axis, bool_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   6679\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   6680\u001b[0m     \u001b[38;5;66;03m# faster equivalent to 'agg_obj.count(agg_axis) > 0'\u001b[39;00m\n\u001b[0;32m   6681\u001b[0m     mask \u001b[38;5;241m=\u001b[39m notna(agg_obj)\u001b[38;5;241m.\u001b[39many(axis\u001b[38;5;241m=\u001b[39magg_axis, bool_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py:460\u001b[0m, in \u001b[0;36mnotna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\n\u001b[1;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241;43m~\u001b[39;49m\u001b[43mres\u001b[49m\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\pandas\\core\\generic.py:1571\u001b[0m, in \u001b[0;36mNDFrame.__invert__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize:\n\u001b[0;32m   1568\u001b[0m     \u001b[38;5;66;03m# inv fails with 0 len\u001b[39;00m\n\u001b[0;32m   1569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m-> 1571\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1572\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   1573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__invert__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:361\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m obj[b\u001b[38;5;241m.\u001b[39mmgr_locs\u001b[38;5;241m.\u001b[39mindexer]\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[1;32m--> 361\u001b[0m     applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.51 GiB for an array with shape (69, 23563668) and data type bool"
     ]
    }
   ],
   "source": [
    "# ---------------- Przygotowanie danych ----------------\n",
    "competition_path = \"M:/PycharmProjects/ds-zt-LGBMRegressor-main/kaggle-dtset\"  # Ścieżka do danych konkursowych\n",
    "batch_size = 1000000  # Rozmiar batcha treningowych\n",
    "percent_of_dataset = 0.2  # Ile procent dataset używamy\n",
    "\n",
    "# Ścieżki do danych\n",
    "train_path = os.path.join(competition_path, \"train.parquet\")\n",
    "test_path = os.path.join(competition_path, \"test.parquet\")\n",
    "features = [f'feature_{i:02}' for i in range(79)]\n",
    "target_train = 'responder_6'  # Target do przewidzenia\n",
    "weights = 'weight'\n",
    "\n",
    "# Wczytanie danych przy użyciu Dask\n",
    "ddf_train = dd.read_parquet(train_path, columns=features + [target_train, weights])\n",
    "data_train = ddf_train.sample(frac=percent_of_dataset, random_state=42).compute()\n",
    "data_train = data_train.dropna(subset=features + [target_train, weights])  # Usunięcie braków\n",
    "\n",
    "X_train = data_train[features]\n",
    "y_train = data_train[target_train]\n",
    "sample_weights_train = data_train[weights]\n",
    "\n",
    "print(f\"Próbka danych: {data_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Próbka danych data_train w wymiarach: (17684990, 81)\n",
      "Próbka danych data_test w wymiarach: (20, 85)\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Parametry GridSearchCV ----------------\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],       # Liczba drzew\n",
    "    'learning_rate': [0.01, 0.05, 0.1],    # Współczynnik uczenia\n",
    "    'num_leaves': [31, 50, 100],           # Liczba liści\n",
    "    'feature_fraction': [0.8, 0.9, 1.0],   # Frakcja cech używanych na drzewo\n",
    "    'subsample': [0.8, 0.9, 1.0],          # Frakcja próbek\n",
    "    'max_depth': [-1, 7, 15],              # Maksymalna głębokość drzewa\n",
    "    'min_child_samples': [20, 30, 50]      # Minimalna liczba próbek w liściu\n",
    "}\n",
    "\n",
    "# Inicjalizacja modelu\n",
    "model = LGBMRegressor(objective='regression', metric='mse', random_state=42)\n",
    "\n",
    "# Skorer dla GridSearchCV\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Cross-validation z podziałem czasowym\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Inicjalizacja GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=mse_scorer,\n",
    "    cv=tscv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Dopasowanie modelu\n",
    "grid_search.fit(X_train, y_train, sample_weight=sample_weights_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolumny w danych treningowym: ['feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78', 'responder_6', 'weight']\n",
      "Kolumny w danych testowych: ['row_id', 'time_id', 'symbol_id', 'weight', 'is_scored', 'feature_00', 'feature_01', 'feature_02', 'feature_03', 'feature_04', 'feature_05', 'feature_06', 'feature_07', 'feature_08', 'feature_09', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78', 'date_id']\n",
      "num_batches: 18\n",
      "Ok - przygotowanie danych zakończone!\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Wyniki GridSearchCV ----------------\n",
    "print(\"\\nNajlepsze parametry:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\nNajlepszy wynik (MSE):\")\n",
    "print(-grid_search.best_score_)\n",
    "\n",
    "# Wyświetlenie wyników dla każdej kombinacji parametrów\n",
    "print(\"\\nWyniki wszystkich prób:\")\n",
    "results = grid_search.cv_results_\n",
    "for mean, std, params in zip(results['mean_test_score'], results['std_test_score'], results['params']):\n",
    "    print(f\"MSE: {-mean:.4f} (std: {std:.4f}) dla parametrów: {params}\")\n",
    "\n",
    "# Zapis wyników do pliku\n",
    "now = datetime.datetime.now()\n",
    "date_str = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "file_name = f\"gridsearch_results_{date_str}.txt\"\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write(f\"Najlepsze parametry: {grid_search.best_params_}\\n\")\n",
    "    f.write(f\"Najlepszy wynik (MSE): {-grid_search.best_score_:.4f}\\n\\n\")\n",
    "    f.write(\"Wyniki wszystkich prób:\\n\")\n",
    "    for mean, std, params in zip(results['mean_test_score'], results['std_test_score'], results['params']):\n",
    "        f.write(f\"MSE: {-mean:.4f} (std: {std:.4f}) dla parametrów: {params}\\n\")\n",
    "\n",
    "print(f\"\\nWyniki zapisano do pliku: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
