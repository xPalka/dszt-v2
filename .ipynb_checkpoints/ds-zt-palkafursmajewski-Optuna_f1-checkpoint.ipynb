{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ok - import\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "import optuna\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.metrics import f1_score, mean_squared_error, mean_squared_error\n",
    "\n",
    "print('Ok - import')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Próbka danych: (2652773, 81)\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Przygotowanie danych ----------------\n",
    "competition_path = \"M:/PycharmProjects/ds-zt-LGBMRegressor-main/kaggle-dtset\"  # Ścieżka do danych konkursowych\n",
    "batch_size = 1000000  # Rozmiar batcha treningowych\n",
    "percent_of_dataset = 0.075  # Ile procent dataset używamy - 7,5%\n",
    "\n",
    "# Ścieżki do danych\n",
    "train_path = os.path.join(competition_path, \"train.parquet\")\n",
    "test_path = os.path.join(competition_path, \"test.parquet\")\n",
    "features = [f'feature_{i:02}' for i in range(79)]\n",
    "target_train = 'responder_6'  # Target do przewidzenia\n",
    "weights = 'weight'\n",
    "\n",
    "# Wczytanie danych przy użyciu Dask\n",
    "ddf_train = dd.read_parquet(train_path, columns=features + [target_train, weights])\n",
    "data_train = ddf_train.sample(frac=percent_of_dataset, random_state=42).compute()\n",
    "data_train = data_train.dropna(subset=features + [target_train, weights])  # Usunięcie braków\n",
    "\n",
    "X_train = data_train[features]\n",
    "y_train = data_train[target_train]\n",
    "sample_weights_train = data_train[weights]\n",
    "\n",
    "print(f\"Próbka danych: {data_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-27 23:52:21,874] A new study created in memory with name: no-name-3e4e2afd-cf8a-471c-8c30-3853ddad1a28\n",
      "[W 2025-01-27 23:52:22,870] Trial 0 failed with parameters: {'n_estimators': 413, 'learning_rate': 0.07344810536313844, 'num_leaves': 67, 'feature_fraction': 0.9241849454756739, 'subsample': 0.8339745798478381, 'max_depth': 8, 'min_child_samples': 47, 'lambda_l1': 1.7297466046738614, 'lambda_l2': 0.010697754025866452, 'max_bin': 162} because of the following error: TypeError(\"LGBMClassifier.fit() got an unexpected keyword argument 'verbose'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"M:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Szymon\\AppData\\Local\\Temp\\ipykernel_20932\\2049778878.py\", line 32, in objective\n",
      "    model.fit(\n",
      "TypeError: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'\n",
      "[W 2025-01-27 23:52:22,874] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LGBMClassifier.fit() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Optymalizacja z Optuna\u001b[39;00m\n\u001b[0;32m     50\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Maksymalizujemy F1-score\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Wyświetlenie najlepszego zestawu parametrów i wyniku\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNajlepsze parametry:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mM:\\PycharmProjects\\ds-zt-LGBMRegressor-main\\venv\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     29\u001b[0m weights_fold_train \u001b[38;5;241m=\u001b[39m sample_weights_train\u001b[38;5;241m.\u001b[39miloc[train_idx]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Dopasowanie modelu\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_fold_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_fold_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fold_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fold_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Metryka logloss\u001b[39;49;00m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Predykcja i obliczenie F1-score\u001b[39;00m\n\u001b[0;32m     42\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_fold_valid)\n",
      "\u001b[1;31mTypeError\u001b[0m: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "# ---------------- Optymalizacja z Optuna ----------------\n",
    "def objective(trial):\n",
    "    # Przestrzeń hiperparametrów\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),           # Liczba drzew\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1), # Współczynnik uczenia\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 31, 100),                # Liczba liści\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.8, 1.0), # Frakcja cech\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.8, 1.0),             # Frakcja próbek\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 15),                   # Maksymalna głębokość\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 50),   # Minimalna liczba próbek w liściu\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-3, 10.0),        # Regularyzacja L1\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-3, 10.0),        # Regularyzacja L2\n",
    "        'max_bin': trial.suggest_int('max_bin', 127, 255),                     # Maksymalna liczba binów\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    # Model LightGBM dla klasyfikacji binarnej\n",
    "    model = LGBMClassifier(objective='binary', **params)\n",
    "\n",
    "    # Cross-validation z podziałem czasowym\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    f1_scores = []\n",
    "    mae_scores = []\n",
    "\n",
    "    for train_idx, valid_idx in tscv.split(X_train):\n",
    "        # Przygotowanie danych treningowych i walidacyjnych\n",
    "        X_fold_train, X_fold_valid = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        y_fold_train, y_fold_valid = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "        weights_fold_train = sample_weights_train.iloc[train_idx]\n",
    "\n",
    "        # Dopasowanie modelu\n",
    "        model.fit(\n",
    "            X_fold_train, y_fold_train,\n",
    "            sample_weight=weights_fold_train,\n",
    "            eval_set=[(X_fold_valid, y_fold_valid)],\n",
    "            eval_metric='logloss',\n",
    "        )\n",
    "\n",
    "        # Predykcje prawdopodobieństw\n",
    "        preds_prob = model.predict_proba(X_fold_valid)[:, 1]  # Prawdopodobieństwo klasy 1\n",
    "        preds_class = (preds_prob > 0.5).astype(int)          # Klasy (0/1)\n",
    "\n",
    "        # Obliczenie F1-score\n",
    "        f1 = f1_score(y_fold_valid, preds_class, average='binary')\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Obliczenie MAE dla prawdopodobieństw\n",
    "        mae = mean_absolute_error(y_fold_valid, preds_prob)\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "    # Zwracamy wynik do optymalizacji (ważymy F1 i MAE, np. 70% F1 + 30% MAE jako przykład)\n",
    "    return 0.7 * np.mean(f1_scores) - 0.3 * np.mean(mae_scores)\n",
    "\n",
    "# Optymalizacja z Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")  # Maksymalizujemy metrykę ważoną\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Wyciąganie najlepszego modelu i metryk dla optymalnych parametrów\n",
    "best_params = study.best_params\n",
    "\n",
    "# Przeprowadzenie walidacji z najlepszymi parametrami\n",
    "model = LGBMClassifier(objective='binary', **best_params)\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "best_f1_scores = []\n",
    "best_mae_scores = []\n",
    "\n",
    "for train_idx, valid_idx in tscv.split(X_train):\n",
    "    X_fold_train, X_fold_valid = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "    y_fold_train, y_fold_valid = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "    weights_fold_train = sample_weights_train.iloc[train_idx]\n",
    "\n",
    "    model.fit(\n",
    "        X_fold_train, y_fold_train,\n",
    "        sample_weight=weights_fold_train,\n",
    "        eval_set=[(X_fold_valid, y_fold_valid)],\n",
    "        eval_metric='logloss',\n",
    "    )\n",
    "\n",
    "    preds_prob = model.predict_proba(X_fold_valid)[:, 1]\n",
    "    preds_class = (preds_prob > 0.5).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_fold_valid, preds_class, average='binary')\n",
    "    mae = mean_absolute_error(y_fold_valid, preds_prob)\n",
    "\n",
    "    best_f1_scores.append(f1)\n",
    "    best_mae_scores.append(mae)\n",
    "\n",
    "# Wyświetlenie najlepszych parametrów i wyników\n",
    "print(\"\\nNajlepsze parametry:\")\n",
    "print(best_params)\n",
    "\n",
    "print(\"\\nNajlepszy średni wynik F1-score dla najlepszych parametrów:\")\n",
    "print(np.mean(best_f1_scores))\n",
    "\n",
    "print(\"\\nNajlepszy średni wynik MAE dla najlepszych parametrów:\")\n",
    "print(np.mean(best_mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Najlepsze parametry:\n",
      "{'n_estimators': 459, 'learning_rate': 0.033441061327066174, 'num_leaves': 85, 'feature_fraction': 0.8086691830052026, 'subsample': 0.9862178362318438, 'max_depth': 9, 'min_child_samples': 25, 'lambda_l1': 0.0049638961104124055, 'lambda_l2': 0.006126150398752788, 'max_bin': 254}\n",
      "\n",
      "Najlepszy wynik (MSE):\n",
      "0.6385294016276032\n",
      "\n",
      "Wyniki zapisano do pliku: optuna_results_2025-01-27-16-10-22.txt\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Wyniki Optuna ----------------\n",
    "print(\"\\nNajlepsze parametry:\")\n",
    "print(study.best_params)\n",
    "\n",
    "print(\"\\nNajlepszy wynik (MSE):\")\n",
    "print(study.best_value)\n",
    "\n",
    "# Zapis wyników do pliku\n",
    "now = datetime.datetime.now()\n",
    "date_str = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "file_name = f\"optuna_results_{date_str}.txt\"\n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write(f\"Najlepsze parametry: {study.best_params}\\n\")\n",
    "    f.write(f\"Najlepszy wynik (MSE): {study.best_value:.4f}\\n\")\n",
    "\n",
    "print(f\"\\nWyniki zapisano do pliku: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
